<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>espnet2.gan_tts package &mdash; ESPnet 202211 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="espnet2.lm package" href="espnet2.lm.html" />
    <link rel="prev" title="espnet2.asr package" href="espnet2.asr.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> ESPnet
          </a>
              <div class="version">
                202211
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallelization.html">Using Job scheduling system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker.html">Docker</a></li>
</ul>
<p><span class="caption-text">ESPnet2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html">ESPnet2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html#instruction-for-run-sh">Instruction for run.sh</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_training_option.html">Change the configuration for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_task.html">Task class and data input system for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_distributed.html">Distributed training</a></li>
</ul>
<p><span class="caption-text">Notebook:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_cli.html">Speech Recognition (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_library.html">Speech Recognition (Library)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_realtime_demo.html">ESPnet2-ASR realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html"><strong>Use transfer learning for ASR in ESPnet2</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#Abstract">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#ESPnet-installation-(about-10-minutes-in-total)">ESPnet installation (about 10 minutes in total)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#mini_an4-recipe-as-a-transfer-learning-example">mini_an4 recipe as a transfer learning example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet-(Almost-same-procedure-as-your-first-tutorial)">Install ESPnet (Almost same procedure as your first tutorial)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#What-we-provide-you-and-what-you-need-to-proceed">What we provide you and what you need to proceed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet">Install ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Run-an-existing-recipe">Run an existing recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Make-a-new-recipe">Make a new recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Additional-resources">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_streaming_asr_demo.html">ESPnet2 real streaming Transformer demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tts_realtime_demo.html">ESPnet2-TTS realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html">CMU 11751/18781 2021: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-an-inference-example">Run an inference example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Full-installation">Full installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-a-recipe-example">Run a recipe example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(1)-Tutorials-on-the-Basic-Usage">(1) Tutorials on the Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(2)-Tutorials-on-Contributing-to-ESPNet-SE-Project">(2) Tutorials on Contributing to ESPNet-SE Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html">espnet_onnx demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Install-Dependency">Install Dependency</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Export-your-model">Export your model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Inference-with-onnx">Inference with onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Using-streaming-model">Using streaming model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/pretrained.html">Pretrained Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/se_demo.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/st_demo.html">ESPnet Speech Translation Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_cli.html">Text-to-Speech (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_realtime_demo.html">ESPnet real time E2E-TTS demonstration</a></li>
</ul>
<p><span class="caption-text">Package Reference:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="espnet.scheduler.html">espnet.scheduler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.nets.html">espnet.nets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.asr.html">espnet.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.transform.html">espnet.transform package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.lm.html">espnet.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.st.html">espnet.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.utils.html">espnet.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.optimizer.html">espnet.optimizer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.tts.html">espnet.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.vc.html">espnet.vc package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.bin.html">espnet.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.mt.html">espnet.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.distributed.html">espnet.distributed package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fileio.html">espnet2.fileio package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.asr.html">espnet2.asr package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">espnet2.gan_tts package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-init">espnet2.gan_tts.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-abs-gan-tts">espnet2.gan_tts.abs_gan_tts</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-espnet-model">espnet2.gan_tts.espnet_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-hifigan-loss">espnet2.gan_tts.hifigan.loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-hifigan-init">espnet2.gan_tts.hifigan.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-hifigan-hifigan">espnet2.gan_tts.hifigan.hifigan</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-hifigan-residual-block">espnet2.gan_tts.hifigan.residual_block</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-wavenet-init">espnet2.gan_tts.wavenet.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-wavenet-wavenet">espnet2.gan_tts.wavenet.wavenet</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-wavenet-residual-block">espnet2.gan_tts.wavenet.residual_block</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-parallel-wavegan-init">espnet2.gan_tts.parallel_wavegan.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-parallel-wavegan-upsample">espnet2.gan_tts.parallel_wavegan.upsample</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-parallel-wavegan-parallel-wavegan">espnet2.gan_tts.parallel_wavegan.parallel_wavegan</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-utils-init">espnet2.gan_tts.utils.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-utils-get-random-segments">espnet2.gan_tts.utils.get_random_segments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-melgan-residual-stack">espnet2.gan_tts.melgan.residual_stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-melgan-init">espnet2.gan_tts.melgan.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-melgan-stft-loss">espnet2.gan_tts.melgan.stft_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-melgan-pqmf">espnet2.gan_tts.melgan.pqmf</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-melgan-melgan">espnet2.gan_tts.melgan.melgan</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-other-vocoder-init">espnet2.gan_tts.other_vocoder.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-other-vocoder-istft-vocoder">espnet2.gan_tts.other_vocoder.istft_vocoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-other-vocoder-bigvgan">espnet2.gan_tts.other_vocoder.bigvgan</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-other-vocoder-stft">espnet2.gan_tts.other_vocoder.stft</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-loss">espnet2.gan_tts.vits.loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-flow">espnet2.gan_tts.vits.flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-init">espnet2.gan_tts.vits.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-duration-predictor">espnet2.gan_tts.vits.duration_predictor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-text-encoder">espnet2.gan_tts.vits.text_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-transform">espnet2.gan_tts.vits.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-posterior-encoder">espnet2.gan_tts.vits.posterior_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-residual-coupling">espnet2.gan_tts.vits.residual_coupling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-vits">espnet2.gan_tts.vits.vits</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-generator">espnet2.gan_tts.vits.generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-monotonic-align-init">espnet2.gan_tts.vits.monotonic_align.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-monotonic-align-setup">espnet2.gan_tts.vits.monotonic_align.setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-style-melgan-init">espnet2.gan_tts.style_melgan.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-style-melgan-style-melgan">espnet2.gan_tts.style_melgan.style_melgan</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-style-melgan-tade-res-block">espnet2.gan_tts.style_melgan.tade_res_block</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-joint-joint-text2wav">espnet2.gan_tts.joint.joint_text2wav</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-joint-init">espnet2.gan_tts.joint.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-jets-loss">espnet2.gan_tts.jets.loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-jets-init">espnet2.gan_tts.jets.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-jets-length-regulator">espnet2.gan_tts.jets.length_regulator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-jets-jets">espnet2.gan_tts.jets.jets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-jets-alignments">espnet2.gan_tts.jets.alignments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-jets-multi-emotion-generator">espnet2.gan_tts.jets.multi_emotion_generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-jets-generator">espnet2.gan_tts.jets.generator</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.lm.html">espnet2.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.st.html">espnet2.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.utils.html">espnet2.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.layers.html">espnet2.layers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.samplers.html">espnet2.samplers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.optimizers.html">espnet2.optimizers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fst.html">espnet2.fst package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.text.html">espnet2.text package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.schedulers.html">espnet2.schedulers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tts.html">espnet2.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.torch_utils.html">espnet2.torch_utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.bin.html">espnet2.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.iterators.html">espnet2.iterators package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.main_funcs.html">espnet2.main_funcs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.hubert.html">espnet2.hubert package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tasks.html">espnet2.tasks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.slu.html">espnet2.slu package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.train.html">espnet2.train package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.asr_transducer.html">espnet2.asr_transducer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.enh.html">espnet2.enh package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.diar.html">espnet2.diar package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.mt.html">espnet2.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.svs.html">espnet2.svs package</a></li>
</ul>
<p><span class="caption-text">Tool Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet_bin.html">core tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet2_bin.html">core tools (espnet2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_py.html">python utility tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_sh.html">bash utility tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ESPnet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">espnet2.gan_tts package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/_gen/espnet2.gan_tts.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="espnet2-gan-tts-package">
<h1>espnet2.gan_tts package<a class="headerlink" href="#espnet2-gan-tts-package" title="Permalink to this headline">¶</a></h1>
<section id="espnet2-gan-tts-init">
<span id="id1"></span><h2>espnet2.gan_tts.__init__<a class="headerlink" href="#espnet2-gan-tts-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.__init__"></span></section>
<section id="espnet2-gan-tts-abs-gan-tts">
<span id="id2"></span><h2>espnet2.gan_tts.abs_gan_tts<a class="headerlink" href="#espnet2-gan-tts-abs-gan-tts" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.abs_gan_tts"></span><p>GAN-based TTS abstrast class.</p>
<dl class="class">
<dt id="espnet2.gan_tts.abs_gan_tts.AbsGANTTS">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.abs_gan_tts.</code><code class="sig-name descname">AbsGANTTS</code><a class="reference internal" href="../_modules/espnet2/gan_tts/abs_gan_tts.html#AbsGANTTS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.abs_gan_tts.AbsGANTTS" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet2.tts.html#espnet2.tts.abs_tts.AbsTTS" title="espnet2.tts.abs_tts.AbsTTS"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.tts.abs_tts.AbsTTS</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>GAN-based TTS model abstract class.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.gan_tts.abs_gan_tts.AbsGANTTS.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">forward_generator</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor], int]]<a class="reference internal" href="../_modules/espnet2/gan_tts/abs_gan_tts.html#AbsGANTTS.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.abs_gan_tts.AbsGANTTS.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Return generator or discriminator loss.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-espnet-model">
<span id="id3"></span><h2>espnet2.gan_tts.espnet_model<a class="headerlink" href="#espnet2-gan-tts-espnet-model" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.espnet_model"></span><p>GAN-based text-to-speech ESPnet model.</p>
<dl class="class">
<dt id="espnet2.gan_tts.espnet_model.ESPnetGANTTSModel">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.espnet_model.</code><code class="sig-name descname">ESPnetGANTTSModel</code><span class="sig-paren">(</span><em class="sig-param">feats_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], normalize: Optional[espnet2.layers.inversible_interface.InversibleInterface], pitch_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], pitch_normalize: Optional[espnet2.layers.inversible_interface.InversibleInterface], energy_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], energy_normalize: Optional[espnet2.layers.inversible_interface.InversibleInterface], tts: espnet2.gan_tts.abs_gan_tts.AbsGANTTS</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/espnet_model.html#ESPnetGANTTSModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.espnet_model.ESPnetGANTTSModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet2.train.html#espnet2.train.abs_gan_espnet_model.AbsGANESPnetModel" title="espnet2.train.abs_gan_espnet_model.AbsGANESPnetModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.train.abs_gan_espnet_model.AbsGANESPnetModel</span></code></a></p>
<p>ESPnet model for GAN-based text-to-speech task.</p>
<p>Initialize ESPnetGANTTSModel module.</p>
<dl class="method">
<dt id="espnet2.gan_tts.espnet_model.ESPnetGANTTSModel.collect_feats">
<code class="sig-name descname">collect_feats</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">durations: Optional[torch.Tensor] = None</em>, <em class="sig-param">durations_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/espnet_model.html#ESPnetGANTTSModel.collect_feats"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.espnet_model.ESPnetGANTTSModel.collect_feats" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate features and return them as a dict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>speech</strong> (<em>Tensor</em>) – Speech waveform tensor (B, T_wav).</p></li>
<li><p><strong>speech_lengths</strong> (<em>Tensor</em>) – Speech length tensor (B, 1).</p></li>
<li><p><strong>durations</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Duration tensor.</p></li>
<li><p><strong>durations_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Duration length tensor (B,).</p></li>
<li><p><strong>pitch</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Pitch tensor.</p></li>
<li><p><strong>pitch_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Pitch length tensor (B,).</p></li>
<li><p><strong>energy</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Energy tensor.</p></li>
<li><p><strong>energy_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Energy length tensor (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (B, D).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker index tensor (B, 1).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Language ID tensor (B, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict of features.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.espnet_model.ESPnetGANTTSModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">durations: Optional[torch.Tensor] = None</em>, <em class="sig-param">durations_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">forward_generator: bool = True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/espnet2/gan_tts/espnet_model.html#ESPnetGANTTSModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.espnet_model.ESPnetGANTTSModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Return generator or discriminator loss with dict format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>speech</strong> (<em>Tensor</em>) – Speech waveform tensor (B, T_wav).</p></li>
<li><p><strong>speech_lengths</strong> (<em>Tensor</em>) – Speech length tensor (B,).</p></li>
<li><p><strong>duration</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Duration tensor.</p></li>
<li><p><strong>duration_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Duration length tensor (B,).</p></li>
<li><p><strong>pitch</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Pitch tensor.</p></li>
<li><p><strong>pitch_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Pitch length tensor (B,).</p></li>
<li><p><strong>energy</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Energy tensor.</p></li>
<li><p><strong>energy_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Energy length tensor (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (B, D).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker ID tensor (B, 1).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Language ID tensor (B, 1).</p></li>
<li><p><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</p></li>
<li><p><strong>kwargs</strong> – “utt_id” is among the input.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>loss (Tensor): Loss scalar tensor.</p></li>
<li><p>stats (Dict[str, float]): Statistics to be monitored.</p></li>
<li><p>weight (Tensor): Weight tensor to summarize losses.</p></li>
<li><p>optim_idx (int): Optimizer index (0 for G and 1 for D).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-hifigan-loss">
<span id="id4"></span><h2>espnet2.gan_tts.hifigan.loss<a class="headerlink" href="#espnet2-gan-tts-hifigan-loss" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.hifigan.loss"></span><p>HiFiGAN-related loss modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.hifigan.loss.DiscriminatorAdversarialLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.loss.</code><code class="sig-name descname">DiscriminatorAdversarialLoss</code><span class="sig-paren">(</span><em class="sig-param">average_by_discriminators: bool = True</em>, <em class="sig-param">loss_type: str = 'mse'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#DiscriminatorAdversarialLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.DiscriminatorAdversarialLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Discriminator adversarial loss module.</p>
<p>Initialize DiscriminatorAversarialLoss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>average_by_discriminators</strong> (<em>bool</em>) – Whether to average the loss by
the number of discriminators.</p></li>
<li><p><strong>loss_type</strong> (<em>str</em>) – Loss type, “mse” or “hinge”.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.loss.DiscriminatorAdversarialLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">outputs_hat: Union[List[List[torch.Tensor]], List[torch.Tensor], torch.Tensor], outputs: Union[List[List[torch.Tensor]], List[torch.Tensor], torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#DiscriminatorAdversarialLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.DiscriminatorAdversarialLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calcualate discriminator adversarial loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs_hat</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – Discriminator
outputs, list of discriminator outputs, or list of list of discriminator
outputs calculated from generator.</p></li>
<li><p><strong>outputs</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – Discriminator
outputs, list of discriminator outputs, or list of list of discriminator
outputs calculated from groundtruth.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Discriminator real loss value.
Tensor: Discriminator fake loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.loss.FeatureMatchLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.loss.</code><code class="sig-name descname">FeatureMatchLoss</code><span class="sig-paren">(</span><em class="sig-param">average_by_layers: bool = True</em>, <em class="sig-param">average_by_discriminators: bool = True</em>, <em class="sig-param">include_final_outputs: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#FeatureMatchLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.FeatureMatchLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Feature matching loss module.</p>
<p>Initialize FeatureMatchLoss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>average_by_layers</strong> (<em>bool</em>) – Whether to average the loss by the number
of layers.</p></li>
<li><p><strong>average_by_discriminators</strong> (<em>bool</em>) – Whether to average the loss by
the number of discriminators.</p></li>
<li><p><strong>include_final_outputs</strong> (<em>bool</em>) – Whether to include the final output of
each discriminator for loss calculation.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.loss.FeatureMatchLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">feats_hat: Union[List[List[torch.Tensor]], List[torch.Tensor]], feats: Union[List[List[torch.Tensor]], List[torch.Tensor]]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#FeatureMatchLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.FeatureMatchLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate feature matching loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feats_hat</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em>) – List of list of
discriminator outputs or list of discriminator outputs calcuated
from generator’s outputs.</p></li>
<li><p><strong>feats</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em>) – List of list of
discriminator outputs or list of discriminator outputs calcuated
from groundtruth..</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Feature matching loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.loss.GeneratorAdversarialLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.loss.</code><code class="sig-name descname">GeneratorAdversarialLoss</code><span class="sig-paren">(</span><em class="sig-param">average_by_discriminators: bool = True</em>, <em class="sig-param">loss_type: str = 'mse'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#GeneratorAdversarialLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.GeneratorAdversarialLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Generator adversarial loss module.</p>
<p>Initialize GeneratorAversarialLoss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>average_by_discriminators</strong> (<em>bool</em>) – Whether to average the loss by
the number of discriminators.</p></li>
<li><p><strong>loss_type</strong> (<em>str</em>) – Loss type, “mse” or “hinge”.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.loss.GeneratorAdversarialLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">outputs: Union[List[List[torch.Tensor]], List[torch.Tensor], torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#GeneratorAdversarialLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.GeneratorAdversarialLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calcualate generator adversarial loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>outputs</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – Discriminator
outputs, list of discriminator outputs, or list of list of discriminator
outputs..</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Generator adversarial loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.loss.MelSpectrogramLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.loss.</code><code class="sig-name descname">MelSpectrogramLoss</code><span class="sig-paren">(</span><em class="sig-param">fs: int = 22050</em>, <em class="sig-param">n_fft: int = 1024</em>, <em class="sig-param">hop_length: int = 256</em>, <em class="sig-param">win_length: Optional[int] = None</em>, <em class="sig-param">window: str = 'hann'</em>, <em class="sig-param">n_mels: int = 80</em>, <em class="sig-param">fmin: Optional[int] = 0</em>, <em class="sig-param">fmax: Optional[int] = None</em>, <em class="sig-param">center: bool = True</em>, <em class="sig-param">normalized: bool = False</em>, <em class="sig-param">onesided: bool = True</em>, <em class="sig-param">log_base: Optional[float] = 10.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#MelSpectrogramLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.MelSpectrogramLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Mel-spectrogram loss.</p>
<p>Initialize Mel-spectrogram loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fs</strong> (<em>int</em>) – Sampling rate.</p></li>
<li><p><strong>n_fft</strong> (<em>int</em>) – FFT points.</p></li>
<li><p><strong>hop_length</strong> (<em>int</em>) – Hop length.</p></li>
<li><p><strong>win_length</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Window length.</p></li>
<li><p><strong>window</strong> (<em>str</em>) – Window type.</p></li>
<li><p><strong>n_mels</strong> (<em>int</em>) – Number of Mel basis.</p></li>
<li><p><strong>fmin</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Minimum frequency for Mel.</p></li>
<li><p><strong>fmax</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Maximum frequency for Mel.</p></li>
<li><p><strong>center</strong> (<em>bool</em>) – Whether to use center window.</p></li>
<li><p><strong>normalized</strong> (<em>bool</em>) – Whether to use normalized one.</p></li>
<li><p><strong>onesided</strong> (<em>bool</em>) – Whether to use oneseded one.</p></li>
<li><p><strong>log_base</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – Log base value.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.loss.MelSpectrogramLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">y_hat: torch.Tensor</em>, <em class="sig-param">y: torch.Tensor</em>, <em class="sig-param">spec: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#MelSpectrogramLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.MelSpectrogramLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate Mel-spectrogram loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_hat</strong> (<em>Tensor</em>) – Generated waveform tensor (B, 1, T).</p></li>
<li><p><strong>y</strong> (<em>Tensor</em>) – Groundtruth waveform tensor (B, 1, T).</p></li>
<li><p><strong>spec</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Groundtruth linear amplitude spectrum tensor
(B, n_fft, T). if provided, use it instead of groundtruth waveform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mel-spectrogram loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-hifigan-init">
<span id="id5"></span><h2>espnet2.gan_tts.hifigan.__init__<a class="headerlink" href="#espnet2-gan-tts-hifigan-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.hifigan.__init__"></span><dl class="class">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.__init__.</code><code class="sig-name descname">HiFiGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 80, out_channels: int = 1, channels: int = 512, global_channels: int = -1, kernel_size: int = 7, upsample_scales: List[int] = [8, 8, 2, 2], upsample_kernel_sizes: List[int] = [16, 16, 4, 4], resblock_kernel_sizes: List[int] = [3, 7, 11], resblock_dilations: List[List[int]] = [[1, 3, 5], [1, 3, 5], [1, 3, 5]], use_additional_convs: bool = True, bias: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFiGAN generator module.</p>
<p>Initialize HiFiGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of hidden representation channels.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of initial and final conv layer.</p></li>
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>upsample_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for upsample layers.</p></li>
<li><p><strong>resblock_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for residual blocks.</p></li>
<li><p><strong>resblock_dilations</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of list of dilations for residual
blocks.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers in
residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>torch.Tensor</em>) – Input tensor (T, in_channels).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (T ** upsample_factor, out_channels).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows the official implementation manner.
<a class="reference external" href="https://github.com/jik876/hifi-gan/blob/master/models.py">https://github.com/jik876/hifi-gan/blob/master/models.py</a></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANMultiPeriodDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.__init__.</code><code class="sig-name descname">HiFiGANMultiPeriodDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">periods: List[int] = [2, 3, 5, 7, 11], discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiPeriodDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANMultiPeriodDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFiGAN multi-period discriminator module.</p>
<p>Initialize HiFiGANMultiPeriodDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>periods</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of periods.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for hifi-gan period
discriminator module. The period parameter will be overwritten.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANMultiPeriodDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiPeriodDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANMultiPeriodDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs, which consists of each</dt><dd><p>layer output tensors.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.__init__.</code><code class="sig-name descname">HiFiGANMultiScaleDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">scales: int = 3, downsample_pooling: str = 'AvgPool1d', downsample_pooling_params: Dict[str, Any] = {'kernel_size': 4, 'padding': 2, 'stride': 2}, discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1}, follow_official_norm: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFi-GAN multi-scale discriminator module.</p>
<p>Initilize HiFiGAN multi-scale discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scales</strong> (<em>int</em>) – Number of multi-scales.</p></li>
<li><p><strong>downsample_pooling</strong> (<em>str</em>) – Pooling module name for downsampling of the
inputs.</p></li>
<li><p><strong>downsample_pooling_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the above pooling
module.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for hifi-gan scale
discriminator module.</p></li>
<li><p><strong>follow_official_norm</strong> (<em>bool</em>) – Whether to follow the norm setting of the
official implementaion. The first discriminator uses spectral norm
and the other discriminators use weight norm.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs,</dt><dd><p>which consists of eachlayer output tensors.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[List[torch.Tensor]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleMultiPeriodDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.__init__.</code><code class="sig-name descname">HiFiGANMultiScaleMultiPeriodDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">scales: int = 3, scale_downsample_pooling: str = 'AvgPool1d', scale_downsample_pooling_params: Dict[str, Any] = {'kernel_size': 4, 'padding': 2, 'stride': 2}, scale_discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1}, follow_official_norm: bool = True, periods: List[int] = [2, 3, 5, 7, 11], period_discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleMultiPeriodDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleMultiPeriodDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFi-GAN multi-scale + multi-period discriminator module.</p>
<p>Initilize HiFiGAN multi-scale + multi-period discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scales</strong> (<em>int</em>) – Number of multi-scales.</p></li>
<li><p><strong>scale_downsample_pooling</strong> (<em>str</em>) – Pooling module name for downsampling of the
inputs.</p></li>
<li><p><strong>scale_downsample_pooling_params</strong> (<em>dict</em>) – Parameters for the above pooling
module.</p></li>
<li><p><strong>scale_discriminator_params</strong> (<em>dict</em>) – Parameters for hifi-gan scale
discriminator module.</p></li>
<li><p><strong>follow_official_norm</strong> (<em>bool</em>) – Whether to follow the norm setting of the
official implementaion. The first discriminator uses spectral norm and
the other discriminators use weight norm.</p></li>
<li><p><strong>periods</strong> (<em>list</em>) – List of periods.</p></li>
<li><p><strong>period_discriminator_params</strong> (<em>dict</em>) – Parameters for hifi-gan period
discriminator module. The period parameter will be overwritten.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleMultiPeriodDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleMultiPeriodDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleMultiPeriodDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs,</dt><dd><p>which consists of each layer output tensors. Multi scale and
multi period ones are concatenated.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[List[Tensor]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.__init__.</code><code class="sig-name descname">HiFiGANPeriodDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1, out_channels: int = 1, period: int = 3, kernel_sizes: List[int] = [5, 3], channels: int = 32, downsample_scales: List[int] = [3, 3, 3, 3, 1], max_downsample_channels: int = 1024, bias: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True, use_spectral_norm: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFiGAN period discriminator module.</p>
<p>Initialize HiFiGANPeriodDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>period</strong> (<em>int</em>) – Period.</p></li>
<li><p><strong>kernel_sizes</strong> (<em>list</em>) – Kernel sizes of initial conv layers and the final conv
layer.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of initial channels.</p></li>
<li><p><strong>downsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of downsampling scales.</p></li>
<li><p><strong>max_downsample_channels</strong> (<em>int</em>) – Number of maximum downsampling channels.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers in
residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
<li><p><strong>use_spectral_norm</strong> (<em>bool</em>) – Whether to use spectral norm.
If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator.apply_spectral_norm">
<code class="sig-name descname">apply_spectral_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator.apply_spectral_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator.apply_spectral_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply spectral normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of each layer’s tensors.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.__init__.</code><code class="sig-name descname">HiFiGANScaleDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1, out_channels: int = 1, kernel_sizes: List[int] = [15, 41, 5, 3], channels: int = 128, max_downsample_channels: int = 1024, max_groups: int = 16, bias: int = True, downsample_scales: List[int] = [2, 2, 4, 4, 1], nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True, use_spectral_norm: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFi-GAN scale discriminator module.</p>
<p>Initilize HiFiGAN scale discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of four kernel sizes. The first will be used
for the first conv layer, and the second is for downsampling part, and
the remaining two are for the last two output layers.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Initial number of channels for conv layer.</p></li>
<li><p><strong>max_downsample_channels</strong> (<em>int</em>) – Maximum number of channels for downsampling
layers.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>downsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of downsampling scales.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
<li><p><strong>use_spectral_norm</strong> (<em>bool</em>) – Whether to use spectral norm. If set to true, it
will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator.apply_spectral_norm">
<code class="sig-name descname">apply_spectral_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator.apply_spectral_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator.apply_spectral_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply spectral normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of output tensors of each layer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-hifigan-hifigan">
<span id="id6"></span><h2>espnet2.gan_tts.hifigan.hifigan<a class="headerlink" href="#espnet2-gan-tts-hifigan-hifigan" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.hifigan.hifigan"></span><p>HiFi-GAN Modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.hifigan.</code><code class="sig-name descname">HiFiGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 80, out_channels: int = 1, channels: int = 512, global_channels: int = -1, kernel_size: int = 7, upsample_scales: List[int] = [8, 8, 2, 2], upsample_kernel_sizes: List[int] = [16, 16, 4, 4], resblock_kernel_sizes: List[int] = [3, 7, 11], resblock_dilations: List[List[int]] = [[1, 3, 5], [1, 3, 5], [1, 3, 5]], use_additional_convs: bool = True, bias: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFiGAN generator module.</p>
<p>Initialize HiFiGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of hidden representation channels.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of initial and final conv layer.</p></li>
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>upsample_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for upsample layers.</p></li>
<li><p><strong>resblock_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for residual blocks.</p></li>
<li><p><strong>resblock_dilations</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of list of dilations for residual
blocks.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers in
residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>torch.Tensor</em>) – Input tensor (T, in_channels).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (T ** upsample_factor, out_channels).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows the official implementation manner.
<a class="reference external" href="https://github.com/jik876/hifi-gan/blob/master/models.py">https://github.com/jik876/hifi-gan/blob/master/models.py</a></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiPeriodDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.hifigan.</code><code class="sig-name descname">HiFiGANMultiPeriodDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">periods: List[int] = [2, 3, 5, 7, 11], discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiPeriodDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiPeriodDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFiGAN multi-period discriminator module.</p>
<p>Initialize HiFiGANMultiPeriodDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>periods</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of periods.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for hifi-gan period
discriminator module. The period parameter will be overwritten.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiPeriodDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiPeriodDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiPeriodDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs, which consists of each</dt><dd><p>layer output tensors.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.hifigan.</code><code class="sig-name descname">HiFiGANMultiScaleDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">scales: int = 3, downsample_pooling: str = 'AvgPool1d', downsample_pooling_params: Dict[str, Any] = {'kernel_size': 4, 'padding': 2, 'stride': 2}, discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1}, follow_official_norm: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFi-GAN multi-scale discriminator module.</p>
<p>Initilize HiFiGAN multi-scale discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scales</strong> (<em>int</em>) – Number of multi-scales.</p></li>
<li><p><strong>downsample_pooling</strong> (<em>str</em>) – Pooling module name for downsampling of the
inputs.</p></li>
<li><p><strong>downsample_pooling_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the above pooling
module.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for hifi-gan scale
discriminator module.</p></li>
<li><p><strong>follow_official_norm</strong> (<em>bool</em>) – Whether to follow the norm setting of the
official implementaion. The first discriminator uses spectral norm
and the other discriminators use weight norm.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs,</dt><dd><p>which consists of eachlayer output tensors.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[List[torch.Tensor]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleMultiPeriodDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.hifigan.</code><code class="sig-name descname">HiFiGANMultiScaleMultiPeriodDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">scales: int = 3, scale_downsample_pooling: str = 'AvgPool1d', scale_downsample_pooling_params: Dict[str, Any] = {'kernel_size': 4, 'padding': 2, 'stride': 2}, scale_discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1}, follow_official_norm: bool = True, periods: List[int] = [2, 3, 5, 7, 11], period_discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleMultiPeriodDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleMultiPeriodDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFi-GAN multi-scale + multi-period discriminator module.</p>
<p>Initilize HiFiGAN multi-scale + multi-period discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scales</strong> (<em>int</em>) – Number of multi-scales.</p></li>
<li><p><strong>scale_downsample_pooling</strong> (<em>str</em>) – Pooling module name for downsampling of the
inputs.</p></li>
<li><p><strong>scale_downsample_pooling_params</strong> (<em>dict</em>) – Parameters for the above pooling
module.</p></li>
<li><p><strong>scale_discriminator_params</strong> (<em>dict</em>) – Parameters for hifi-gan scale
discriminator module.</p></li>
<li><p><strong>follow_official_norm</strong> (<em>bool</em>) – Whether to follow the norm setting of the
official implementaion. The first discriminator uses spectral norm and
the other discriminators use weight norm.</p></li>
<li><p><strong>periods</strong> (<em>list</em>) – List of periods.</p></li>
<li><p><strong>period_discriminator_params</strong> (<em>dict</em>) – Parameters for hifi-gan period
discriminator module. The period parameter will be overwritten.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleMultiPeriodDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleMultiPeriodDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleMultiPeriodDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs,</dt><dd><p>which consists of each layer output tensors. Multi scale and
multi period ones are concatenated.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[List[Tensor]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.hifigan.</code><code class="sig-name descname">HiFiGANPeriodDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1, out_channels: int = 1, period: int = 3, kernel_sizes: List[int] = [5, 3], channels: int = 32, downsample_scales: List[int] = [3, 3, 3, 3, 1], max_downsample_channels: int = 1024, bias: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True, use_spectral_norm: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFiGAN period discriminator module.</p>
<p>Initialize HiFiGANPeriodDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>period</strong> (<em>int</em>) – Period.</p></li>
<li><p><strong>kernel_sizes</strong> (<em>list</em>) – Kernel sizes of initial conv layers and the final conv
layer.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of initial channels.</p></li>
<li><p><strong>downsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of downsampling scales.</p></li>
<li><p><strong>max_downsample_channels</strong> (<em>int</em>) – Number of maximum downsampling channels.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers in
residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
<li><p><strong>use_spectral_norm</strong> (<em>bool</em>) – Whether to use spectral norm.
If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator.apply_spectral_norm">
<code class="sig-name descname">apply_spectral_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator.apply_spectral_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator.apply_spectral_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply spectral normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of each layer’s tensors.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.hifigan.</code><code class="sig-name descname">HiFiGANScaleDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1, out_channels: int = 1, kernel_sizes: List[int] = [15, 41, 5, 3], channels: int = 128, max_downsample_channels: int = 1024, max_groups: int = 16, bias: int = True, downsample_scales: List[int] = [2, 2, 4, 4, 1], nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True, use_spectral_norm: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFi-GAN scale discriminator module.</p>
<p>Initilize HiFiGAN scale discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of four kernel sizes. The first will be used
for the first conv layer, and the second is for downsampling part, and
the remaining two are for the last two output layers.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Initial number of channels for conv layer.</p></li>
<li><p><strong>max_downsample_channels</strong> (<em>int</em>) – Maximum number of channels for downsampling
layers.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>downsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of downsampling scales.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
<li><p><strong>use_spectral_norm</strong> (<em>bool</em>) – Whether to use spectral norm. If set to true, it
will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator.apply_spectral_norm">
<code class="sig-name descname">apply_spectral_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator.apply_spectral_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator.apply_spectral_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply spectral normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of output tensors of each layer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-hifigan-residual-block">
<span id="id7"></span><h2>espnet2.gan_tts.hifigan.residual_block<a class="headerlink" href="#espnet2-gan-tts-hifigan-residual-block" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.hifigan.residual_block"></span><p>HiFiGAN Residual block modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.hifigan.residual_block.ResidualBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.residual_block.</code><code class="sig-name descname">ResidualBlock</code><span class="sig-paren">(</span><em class="sig-param">kernel_size: int = 3, channels: int = 512, dilations: List[int] = [1, 3, 5], bias: bool = True, use_additional_convs: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/residual_block.html#ResidualBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.residual_block.ResidualBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Residual block module in HiFiGAN.</p>
<p>Initialize ResidualBlock module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of dilation convolution layer.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of channels for convolution layer.</p></li>
<li><p><strong>dilations</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of dilation factors.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional convolution layers.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.residual_block.ResidualBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/residual_block.html#ResidualBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.residual_block.ResidualBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, channels, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, channels, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-wavenet-init">
<span id="id8"></span><h2>espnet2.gan_tts.wavenet.__init__<a class="headerlink" href="#espnet2-gan-tts-wavenet-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.wavenet.__init__"></span></section>
<section id="espnet2-gan-tts-wavenet-wavenet">
<span id="id9"></span><h2>espnet2.gan_tts.wavenet.wavenet<a class="headerlink" href="#espnet2-gan-tts-wavenet-wavenet" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.wavenet.wavenet"></span><p>WaveNet modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.wavenet.wavenet.WaveNet">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.wavenet.wavenet.</code><code class="sig-name descname">WaveNet</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1</em>, <em class="sig-param">out_channels: int = 1</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">layers: int = 30</em>, <em class="sig-param">stacks: int = 3</em>, <em class="sig-param">base_dilation: int = 2</em>, <em class="sig-param">residual_channels: int = 64</em>, <em class="sig-param">aux_channels: int = -1</em>, <em class="sig-param">gate_channels: int = 128</em>, <em class="sig-param">skip_channels: int = 64</em>, <em class="sig-param">global_channels: int = -1</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">use_weight_norm: bool = True</em>, <em class="sig-param">use_first_conv: bool = False</em>, <em class="sig-param">use_last_conv: bool = False</em>, <em class="sig-param">scale_residual: bool = False</em>, <em class="sig-param">scale_skip_connect: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/wavenet.html#WaveNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.wavenet.WaveNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>WaveNet with global conditioning.</p>
<p>Initialize WaveNet module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of dilated convolution.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of residual block layers.</p></li>
<li><p><strong>stacks</strong> (<em>int</em>) – Number of stacks i.e., dilation cycles.</p></li>
<li><p><strong>base_dilation</strong> (<em>int</em>) – Base dilation factor.</p></li>
<li><p><strong>residual_channels</strong> (<em>int</em>) – Number of channels in residual conv.</p></li>
<li><p><strong>gate_channels</strong> (<em>int</em>) – Number of channels in gated conv.</p></li>
<li><p><strong>skip_channels</strong> (<em>int</em>) – Number of channels in skip conv.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of channels for local conditioning feature.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of channels for global conditioning feature.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate. 0.0 means no dropout applied.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv layer.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
<li><p><strong>use_first_conv</strong> (<em>bool</em>) – Whether to use the first conv layers.</p></li>
<li><p><strong>use_last_conv</strong> (<em>bool</em>) – Whether to use the last conv layers.</p></li>
<li><p><strong>scale_residual</strong> (<em>bool</em>) – Whether to scale the residual outputs.</p></li>
<li><p><strong>scale_skip_connect</strong> (<em>bool</em>) – Whether to scale the skip connection outputs.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.wavenet.wavenet.WaveNet.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/wavenet.html#WaveNet.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.wavenet.WaveNet.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.wavenet.wavenet.WaveNet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">c: Optional[torch.Tensor] = None</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/wavenet.html#WaveNet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.wavenet.WaveNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T) if use_first_conv else
(B, residual_channels, T).</p></li>
<li><p><strong>x_mask</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Mask tensor (B, 1, T).</p></li>
<li><p><strong>c</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Local conditioning features (B, aux_channels, T).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning features (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Output tensor (B, out_channels, T) if use_last_conv else</dt><dd><p>(B, residual_channels, T).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.wavenet.wavenet.WaveNet.receptive_field_size">
<em class="property">property </em><code class="sig-name descname">receptive_field_size</code><a class="headerlink" href="#espnet2.gan_tts.wavenet.wavenet.WaveNet.receptive_field_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Return receptive field size.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.wavenet.wavenet.WaveNet.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/wavenet.html#WaveNet.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.wavenet.WaveNet.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-wavenet-residual-block">
<span id="id10"></span><h2>espnet2.gan_tts.wavenet.residual_block<a class="headerlink" href="#espnet2-gan-tts-wavenet-residual-block" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.wavenet.residual_block"></span><p>Residual block modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.wavenet.residual_block.Conv1d">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.wavenet.residual_block.</code><code class="sig-name descname">Conv1d</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/residual_block.html#Conv1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.residual_block.Conv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.conv.Conv1d</span></code></p>
<p>Conv1d module with customized initialization.</p>
<p>Initialize Conv1d module.</p>
<dl class="method">
<dt id="espnet2.gan_tts.wavenet.residual_block.Conv1d.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/residual_block.html#Conv1d.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.residual_block.Conv1d.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.wavenet.residual_block.Conv1d1x1">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.wavenet.residual_block.</code><code class="sig-name descname">Conv1d1x1</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int</em>, <em class="sig-param">out_channels: int</em>, <em class="sig-param">bias: bool</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/residual_block.html#Conv1d1x1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.residual_block.Conv1d1x1" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.gan_tts.wavenet.residual_block.Conv1d" title="espnet2.gan_tts.wavenet.residual_block.Conv1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.gan_tts.wavenet.residual_block.Conv1d</span></code></a></p>
<p>1x1 Conv1d with customized initialization.</p>
<p>Initialize 1x1 Conv1d module.</p>
</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.wavenet.residual_block.ResidualBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.wavenet.residual_block.</code><code class="sig-name descname">ResidualBlock</code><span class="sig-paren">(</span><em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">residual_channels: int = 64</em>, <em class="sig-param">gate_channels: int = 128</em>, <em class="sig-param">skip_channels: int = 64</em>, <em class="sig-param">aux_channels: int = 80</em>, <em class="sig-param">global_channels: int = -1</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">dilation: int = 1</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">scale_residual: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/residual_block.html#ResidualBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.residual_block.ResidualBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Residual block module in WaveNet.</p>
<p>Initialize ResidualBlock module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of dilation convolution layer.</p></li>
<li><p><strong>residual_channels</strong> (<em>int</em>) – Number of channels for residual connection.</p></li>
<li><p><strong>skip_channels</strong> (<em>int</em>) – Number of channels for skip connection.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of local conditioning channels.</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout probability.</p></li>
<li><p><strong>dilation</strong> (<em>int</em>) – Dilation factor.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>scale_residual</strong> (<em>bool</em>) – Whether to scale the residual outputs.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.wavenet.residual_block.ResidualBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">c: Optional[torch.Tensor] = None</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/residual_block.html#ResidualBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.residual_block.ResidualBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, residual_channels, T).</p></li>
<li><p><strong>Optional</strong><strong>[</strong><strong>torch.Tensor</strong><strong>]</strong> (<em>x_mask</em>) – Mask tensor (B, 1, T).</p></li>
<li><p><strong>c</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Local conditioning tensor (B, aux_channels, T).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor for residual connection (B, residual_channels, T).
Tensor: Output tensor for skip connection (B, skip_channels, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-parallel-wavegan-init">
<span id="id11"></span><h2>espnet2.gan_tts.parallel_wavegan.__init__<a class="headerlink" href="#espnet2-gan-tts-parallel-wavegan-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.parallel_wavegan.__init__"></span><dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.__init__.</code><code class="sig-name descname">ParallelWaveGANDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1</em>, <em class="sig-param">out_channels: int = 1</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">layers: int = 10</em>, <em class="sig-param">conv_channels: int = 64</em>, <em class="sig-param">dilation_factor: int = 1</em>, <em class="sig-param">nonlinear_activation: str = 'LeakyReLU'</em>, <em class="sig-param">nonlinear_activation_params: Dict[str</em>, <em class="sig-param">Any] = {'negative_slope': 0.2}</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Parallel WaveGAN Discriminator module.</p>
<p>Initialize ParallelWaveGANDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of conv layers.</p></li>
<li><p><strong>conv_channels</strong> (<em>int</em>) – Number of chnn layers.</p></li>
<li><p><strong>dilation_factor</strong> (<em>int</em>) – Dilation factor. For example, if dilation_factor = 2,
the dilation will be 2, 4, 8, …, and so on.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Nonlinear function after each conv.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Nonlinear function parameters</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, 1, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.__init__.</code><code class="sig-name descname">ParallelWaveGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1</em>, <em class="sig-param">out_channels: int = 1</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">layers: int = 30</em>, <em class="sig-param">stacks: int = 3</em>, <em class="sig-param">residual_channels: int = 64</em>, <em class="sig-param">gate_channels: int = 128</em>, <em class="sig-param">skip_channels: int = 64</em>, <em class="sig-param">aux_channels: int = 80</em>, <em class="sig-param">aux_context_window: int = 2</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">use_weight_norm: bool = True</em>, <em class="sig-param">upsample_conditional_features: bool = True</em>, <em class="sig-param">upsample_net: str = 'ConvInUpsampleNetwork'</em>, <em class="sig-param">upsample_params: Dict[str</em>, <em class="sig-param">Any] = {'upsample_scales': [4</em>, <em class="sig-param">4</em>, <em class="sig-param">4</em>, <em class="sig-param">4]}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Parallel WaveGAN Generator module.</p>
<p>Initialize ParallelWaveGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of dilated convolution.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of residual block layers.</p></li>
<li><p><strong>stacks</strong> (<em>int</em>) – Number of stacks i.e., dilation cycles.</p></li>
<li><p><strong>residual_channels</strong> (<em>int</em>) – Number of channels in residual conv.</p></li>
<li><p><strong>gate_channels</strong> (<em>int</em>) – Number of channels in gated conv.</p></li>
<li><p><strong>skip_channels</strong> (<em>int</em>) – Number of channels in skip conv.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of channels for auxiliary feature conv.</p></li>
<li><p><strong>aux_context_window</strong> (<em>int</em>) – Context window size for auxiliary feature.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate. 0.0 means no dropout applied.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv layer.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
<li><p><strong>upsample_conditional_features</strong> (<em>bool</em>) – Whether to use upsampling network.</p></li>
<li><p><strong>upsample_net</strong> (<em>str</em>) – Upsampling network architecture.</p></li>
<li><p><strong>upsample_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Upsampling network parameters.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">z: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Local conditioning auxiliary features (B, C ,T_feats).</p></li>
<li><p><strong>z</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T_wav).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T_wav)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">z: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Local conditioning auxiliary features (T_feats ,C).</p></li>
<li><p><strong>z</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Input noise signal (T_wav, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (T_wav, out_channels)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.receptive_field_size">
<em class="property">property </em><code class="sig-name descname">receptive_field_size</code><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.receptive_field_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Return receptive field size.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-parallel-wavegan-upsample">
<span id="id12"></span><h2>espnet2.gan_tts.parallel_wavegan.upsample<a class="headerlink" href="#espnet2-gan-tts-parallel-wavegan-upsample" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.parallel_wavegan.upsample"></span><p>Upsampling module.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.Conv2d">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.upsample.</code><code class="sig-name descname">Conv2d</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#Conv2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.Conv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.conv.Conv2d</span></code></p>
<p>Conv2d module with customized initialization.</p>
<p>Initialize Conv2d module.</p>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.Conv2d.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#Conv2d.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.Conv2d.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.ConvInUpsampleNetwork">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.upsample.</code><code class="sig-name descname">ConvInUpsampleNetwork</code><span class="sig-paren">(</span><em class="sig-param">upsample_scales: List[int], nonlinear_activation: Optional[str] = None, nonlinear_activation_params: Dict[str, Any] = {}, interpolate_mode: str = 'nearest', freq_axis_kernel_size: int = 1, aux_channels: int = 80, aux_context_window: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#ConvInUpsampleNetwork"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.ConvInUpsampleNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convolution + upsampling network module.</p>
<p>Initialize ConvInUpsampleNetwork module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>upsample_scales</strong> (<em>list</em>) – List of upsampling scales.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Activation function name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Arguments for the specified
activation function.</p></li>
<li><p><strong>mode</strong> (<em>str</em>) – Interpolation mode.</p></li>
<li><p><strong>freq_axis_kernel_size</strong> (<em>int</em>) – Kernel size in the direction of
frequency axis.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of channels of pre-conv layer.</p></li>
<li><p><strong>aux_context_window</strong> (<em>int</em>) – Context window size of the pre-conv layer.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.ConvInUpsampleNetwork.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#ConvInUpsampleNetwork.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.ConvInUpsampleNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, C, T_feats).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Upsampled tensor (B, C, T_wav),</dt><dd><p>where T_wav = T_feats * prod(upsample_scales).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.Stretch2d">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.upsample.</code><code class="sig-name descname">Stretch2d</code><span class="sig-paren">(</span><em class="sig-param">x_scale: int</em>, <em class="sig-param">y_scale: int</em>, <em class="sig-param">mode: str = 'nearest'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#Stretch2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.Stretch2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Stretch2d module.</p>
<p>Initialize Stretch2d module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_scale</strong> (<em>int</em>) – X scaling factor (Time axis in spectrogram).</p></li>
<li><p><strong>y_scale</strong> (<em>int</em>) – Y scaling factor (Frequency axis in spectrogram).</p></li>
<li><p><strong>mode</strong> (<em>str</em>) – Interpolation mode.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.Stretch2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#Stretch2d.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.Stretch2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, C, F, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Interpolated tensor (B, C, F * y_scale, T * x_scale),</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.UpsampleNetwork">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.upsample.</code><code class="sig-name descname">UpsampleNetwork</code><span class="sig-paren">(</span><em class="sig-param">upsample_scales: List[int], nonlinear_activation: Optional[str] = None, nonlinear_activation_params: Dict[str, Any] = {}, interpolate_mode: str = 'nearest', freq_axis_kernel_size: int = 1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#UpsampleNetwork"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.UpsampleNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Upsampling network module.</p>
<p>Initialize UpsampleNetwork module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Activation function name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Arguments for the specified
activation function.</p></li>
<li><p><strong>interpolate_mode</strong> (<em>str</em>) – Interpolation mode.</p></li>
<li><p><strong>freq_axis_kernel_size</strong> (<em>int</em>) – Kernel size in the direction of frequency axis.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.UpsampleNetwork.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#UpsampleNetwork.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.UpsampleNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> – Input tensor (B, C, T_feats).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Upsampled tensor (B, C, T_wav).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-parallel-wavegan-parallel-wavegan">
<span id="id13"></span><h2>espnet2.gan_tts.parallel_wavegan.parallel_wavegan<a class="headerlink" href="#espnet2-gan-tts-parallel-wavegan-parallel-wavegan" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.parallel_wavegan.parallel_wavegan"></span><p>Parallel WaveGAN Modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.parallel_wavegan.</code><code class="sig-name descname">ParallelWaveGANDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1</em>, <em class="sig-param">out_channels: int = 1</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">layers: int = 10</em>, <em class="sig-param">conv_channels: int = 64</em>, <em class="sig-param">dilation_factor: int = 1</em>, <em class="sig-param">nonlinear_activation: str = 'LeakyReLU'</em>, <em class="sig-param">nonlinear_activation_params: Dict[str</em>, <em class="sig-param">Any] = {'negative_slope': 0.2}</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Parallel WaveGAN Discriminator module.</p>
<p>Initialize ParallelWaveGANDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of conv layers.</p></li>
<li><p><strong>conv_channels</strong> (<em>int</em>) – Number of chnn layers.</p></li>
<li><p><strong>dilation_factor</strong> (<em>int</em>) – Dilation factor. For example, if dilation_factor = 2,
the dilation will be 2, 4, 8, …, and so on.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Nonlinear function after each conv.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Nonlinear function parameters</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, 1, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.parallel_wavegan.</code><code class="sig-name descname">ParallelWaveGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1</em>, <em class="sig-param">out_channels: int = 1</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">layers: int = 30</em>, <em class="sig-param">stacks: int = 3</em>, <em class="sig-param">residual_channels: int = 64</em>, <em class="sig-param">gate_channels: int = 128</em>, <em class="sig-param">skip_channels: int = 64</em>, <em class="sig-param">aux_channels: int = 80</em>, <em class="sig-param">aux_context_window: int = 2</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">use_weight_norm: bool = True</em>, <em class="sig-param">upsample_conditional_features: bool = True</em>, <em class="sig-param">upsample_net: str = 'ConvInUpsampleNetwork'</em>, <em class="sig-param">upsample_params: Dict[str</em>, <em class="sig-param">Any] = {'upsample_scales': [4</em>, <em class="sig-param">4</em>, <em class="sig-param">4</em>, <em class="sig-param">4]}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Parallel WaveGAN Generator module.</p>
<p>Initialize ParallelWaveGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of dilated convolution.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of residual block layers.</p></li>
<li><p><strong>stacks</strong> (<em>int</em>) – Number of stacks i.e., dilation cycles.</p></li>
<li><p><strong>residual_channels</strong> (<em>int</em>) – Number of channels in residual conv.</p></li>
<li><p><strong>gate_channels</strong> (<em>int</em>) – Number of channels in gated conv.</p></li>
<li><p><strong>skip_channels</strong> (<em>int</em>) – Number of channels in skip conv.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of channels for auxiliary feature conv.</p></li>
<li><p><strong>aux_context_window</strong> (<em>int</em>) – Context window size for auxiliary feature.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate. 0.0 means no dropout applied.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv layer.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
<li><p><strong>upsample_conditional_features</strong> (<em>bool</em>) – Whether to use upsampling network.</p></li>
<li><p><strong>upsample_net</strong> (<em>str</em>) – Upsampling network architecture.</p></li>
<li><p><strong>upsample_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Upsampling network parameters.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">z: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Local conditioning auxiliary features (B, C ,T_feats).</p></li>
<li><p><strong>z</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T_wav).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T_wav)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">z: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Local conditioning auxiliary features (T_feats ,C).</p></li>
<li><p><strong>z</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Input noise signal (T_wav, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (T_wav, out_channels)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.receptive_field_size">
<em class="property">property </em><code class="sig-name descname">receptive_field_size</code><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.receptive_field_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Return receptive field size.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-utils-init">
<span id="id14"></span><h2>espnet2.gan_tts.utils.__init__<a class="headerlink" href="#espnet2-gan-tts-utils-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.utils.__init__"></span></section>
<section id="espnet2-gan-tts-utils-get-random-segments">
<span id="id15"></span><h2>espnet2.gan_tts.utils.get_random_segments<a class="headerlink" href="#espnet2-gan-tts-utils-get-random-segments" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.utils.get_random_segments"></span><p>Function to get random segments.</p>
<dl class="function">
<dt id="espnet2.gan_tts.utils.get_random_segments.get_random_segments">
<code class="sig-prename descclassname">espnet2.gan_tts.utils.get_random_segments.</code><code class="sig-name descname">get_random_segments</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_lengths: torch.Tensor</em>, <em class="sig-param">segment_size: int</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/utils/get_random_segments.html#get_random_segments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.utils.get_random_segments.get_random_segments" title="Permalink to this definition">¶</a></dt>
<dd><p>Get random segments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, C, T).</p></li>
<li><p><strong>x_lengths</strong> (<em>Tensor</em>) – Length tensor (B,).</p></li>
<li><p><strong>segment_size</strong> (<em>int</em>) – Segment size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Segmented tensor (B, C, segment_size).
Tensor: Start index tensor (B,).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.gan_tts.utils.get_random_segments.get_segments">
<code class="sig-prename descclassname">espnet2.gan_tts.utils.get_random_segments.</code><code class="sig-name descname">get_segments</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">start_idxs: torch.Tensor</em>, <em class="sig-param">segment_size: int</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/utils/get_random_segments.html#get_segments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.utils.get_random_segments.get_segments" title="Permalink to this definition">¶</a></dt>
<dd><p>Get segments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, C, T).</p></li>
<li><p><strong>start_idxs</strong> (<em>Tensor</em>) – Start index tensor (B,).</p></li>
<li><p><strong>segment_size</strong> (<em>int</em>) – Segment size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Segmented tensor (B, C, segment_size).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-gan-tts-melgan-residual-stack">
<span id="id16"></span><h2>espnet2.gan_tts.melgan.residual_stack<a class="headerlink" href="#espnet2-gan-tts-melgan-residual-stack" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.melgan.residual_stack"></span><p>Residual stack module in MelGAN.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.melgan.residual_stack.ResidualStack">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.residual_stack.</code><code class="sig-name descname">ResidualStack</code><span class="sig-paren">(</span><em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">channels: int = 32</em>, <em class="sig-param">dilation: int = 1</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">nonlinear_activation: str = 'LeakyReLU'</em>, <em class="sig-param">nonlinear_activation_params: Dict[str</em>, <em class="sig-param">Any] = {'negative_slope': 0.2}</em>, <em class="sig-param">pad: str = 'ReflectionPad1d'</em>, <em class="sig-param">pad_params: Dict[str</em>, <em class="sig-param">Any] = {}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/residual_stack.html#ResidualStack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.residual_stack.ResidualStack" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Residual stack module introduced in MelGAN.</p>
<p>Initialize ResidualStack module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of dilation convolution layer.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of channels of convolution layers.</p></li>
<li><p><strong>dilation</strong> (<em>int</em>) – Dilation factor.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for
activation function.</p></li>
<li><p><strong>pad</strong> (<em>str</em>) – Padding function module name before dilated convolution layer.</p></li>
<li><p><strong>pad_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for padding function.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.residual_stack.ResidualStack.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/residual_stack.html#ResidualStack.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.residual_stack.ResidualStack.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, channels, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, chennels, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-melgan-init">
<span id="id17"></span><h2>espnet2.gan_tts.melgan.__init__<a class="headerlink" href="#espnet2-gan-tts-melgan-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.melgan.__init__"></span></section>
<section id="espnet2-gan-tts-melgan-stft-loss">
<span id="id18"></span><h2>espnet2.gan_tts.melgan.stft_loss<a class="headerlink" href="#espnet2-gan-tts-melgan-stft-loss" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.melgan.stft_loss"></span><p>STFT-based Loss modules.</p>
<dl class="class">
<dt id="espnet2.gan_tts.melgan.stft_loss.LogSTFTMagnitudeLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.stft_loss.</code><code class="sig-name descname">LogSTFTMagnitudeLoss</code><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/stft_loss.html#LogSTFTMagnitudeLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.stft_loss.LogSTFTMagnitudeLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Log STFT magnitude loss module.</p>
<p>Initilize los STFT magnitude loss module.</p>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.stft_loss.LogSTFTMagnitudeLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x_mag</em>, <em class="sig-param">y_mag</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/stft_loss.html#LogSTFTMagnitudeLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.stft_loss.LogSTFTMagnitudeLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.
:param x_mag: Magnitude spectrogram of predicted signal (B, #frames, #freq_bins).
:type x_mag: Tensor
:param y_mag: Magnitude spectrogram of groundtruth signal (B, #frames, #freq_bins).
:type y_mag: Tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Log STFT magnitude loss value.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.melgan.stft_loss.MultiResolutionSTFTLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.stft_loss.</code><code class="sig-name descname">MultiResolutionSTFTLoss</code><span class="sig-paren">(</span><em class="sig-param">fft_sizes=[1024, 2048, 512], hop_sizes=[120, 240, 50], win_lengths=[600, 1200, 240], window='hann_window'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/stft_loss.html#MultiResolutionSTFTLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.stft_loss.MultiResolutionSTFTLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multi resolution STFT loss module.</p>
<p>Initialize Multi resolution STFT loss module.
:param fft_sizes: List of FFT sizes.
:type fft_sizes: list
:param hop_sizes: List of hop sizes.
:type hop_sizes: list
:param win_lengths: List of window lengths.
:type win_lengths: list
:param window: Window function type.
:type window: str</p>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.stft_loss.MultiResolutionSTFTLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/stft_loss.html#MultiResolutionSTFTLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.stft_loss.MultiResolutionSTFTLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.
:param x: Predicted signal (B, T) or (B, #subband, T).
:type x: Tensor
:param y: Groundtruth signal (B, T) or (B, #subband, T).
:type y: Tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Multi resolution spectral convergence loss value.
Tensor: Multi resolution log STFT magnitude loss value.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.melgan.stft_loss.STFTLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.stft_loss.</code><code class="sig-name descname">STFTLoss</code><span class="sig-paren">(</span><em class="sig-param">fft_size=1024</em>, <em class="sig-param">shift_size=120</em>, <em class="sig-param">win_length=600</em>, <em class="sig-param">window='hann_window'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/stft_loss.html#STFTLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.stft_loss.STFTLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>STFT loss module.</p>
<p>Initialize STFT loss module.</p>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.stft_loss.STFTLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/stft_loss.html#STFTLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.stft_loss.STFTLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.
:param x: Predicted signal (B, T).
:type x: Tensor
:param y: Groundtruth signal (B, T).
:type y: Tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Spectral convergence loss value.
Tensor: Log STFT magnitude loss value.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.melgan.stft_loss.SpectralConvergenceLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.stft_loss.</code><code class="sig-name descname">SpectralConvergenceLoss</code><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/stft_loss.html#SpectralConvergenceLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.stft_loss.SpectralConvergenceLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Spectral convergence loss module.</p>
<p>Initilize spectral convergence loss module.</p>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.stft_loss.SpectralConvergenceLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x_mag</em>, <em class="sig-param">y_mag</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/stft_loss.html#SpectralConvergenceLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.stft_loss.SpectralConvergenceLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.
:param x_mag: Magnitude spectrogram of predicted signal (B, #frames, #freq_bins).
:type x_mag: Tensor
:param y_mag: Magnitude spectrogram of groundtruth signal (B, #frames, #freq_bins).
:type y_mag: Tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Spectral convergence loss value.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.gan_tts.melgan.stft_loss.stft">
<code class="sig-prename descclassname">espnet2.gan_tts.melgan.stft_loss.</code><code class="sig-name descname">stft</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">fft_size</em>, <em class="sig-param">hop_size</em>, <em class="sig-param">win_length</em>, <em class="sig-param">window</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/stft_loss.html#stft"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.stft_loss.stft" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform STFT and convert to magnitude spectrogram.
:param x: Input signal tensor (B, T).
:type x: Tensor
:param fft_size: FFT size.
:type fft_size: int
:param hop_size: Hop size.
:type hop_size: int
:param win_length: Window length.
:type win_length: int
:param window: Window function type.
:type window: str</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Magnitude spectrogram (B, #frames, fft_size // 2 + 1).</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-gan-tts-melgan-pqmf">
<span id="id19"></span><h2>espnet2.gan_tts.melgan.pqmf<a class="headerlink" href="#espnet2-gan-tts-melgan-pqmf" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.melgan.pqmf"></span><p>Pseudo QMF modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.melgan.pqmf.PQMF">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.pqmf.</code><code class="sig-name descname">PQMF</code><span class="sig-paren">(</span><em class="sig-param">subbands: int = 4</em>, <em class="sig-param">taps: int = 62</em>, <em class="sig-param">cutoff_ratio: float = 0.142</em>, <em class="sig-param">beta: float = 9.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/pqmf.html#PQMF"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.pqmf.PQMF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>PQMF module.</p>
<p>This module is based on <a class="reference external" href="https://ieeexplore.ieee.org/document/258122">Near-perfect-reconstruction pseudo-QMF banks</a>.</p>
<p>Initilize PQMF module.</p>
<p>The cutoff_ratio and beta parameters are optimized for #subbands = 4.
See dicussion in <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN/issues/195">https://github.com/kan-bayashi/ParallelWaveGAN/issues/195</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>subbands</strong> (<em>int</em>) – The number of subbands.</p></li>
<li><p><strong>taps</strong> (<em>int</em>) – The number of filter taps.</p></li>
<li><p><strong>cutoff_ratio</strong> (<em>float</em>) – Cut-off frequency ratio.</p></li>
<li><p><strong>beta</strong> (<em>float</em>) – Beta coefficient for kaiser window.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.pqmf.PQMF.analysis">
<code class="sig-name descname">analysis</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/pqmf.html#PQMF.analysis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.pqmf.PQMF.analysis" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis with PQMF.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, subbands, T // subbands).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.pqmf.PQMF.synthesis">
<code class="sig-name descname">synthesis</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/pqmf.html#PQMF.synthesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.pqmf.PQMF.synthesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Synthesis with PQMF.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, subbands, T // subbands).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, 1, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.gan_tts.melgan.pqmf.design_prototype_filter">
<code class="sig-prename descclassname">espnet2.gan_tts.melgan.pqmf.</code><code class="sig-name descname">design_prototype_filter</code><span class="sig-paren">(</span><em class="sig-param">taps: int = 62</em>, <em class="sig-param">cutoff_ratio: float = 0.142</em>, <em class="sig-param">beta: float = 9.0</em><span class="sig-paren">)</span> &#x2192; numpy.ndarray<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/pqmf.html#design_prototype_filter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.pqmf.design_prototype_filter" title="Permalink to this definition">¶</a></dt>
<dd><p>Design prototype filter for PQMF.</p>
<p>This method is based on <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/681427">A Kaiser window approach for the design of prototype
filters of cosine modulated filterbanks</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>taps</strong> (<em>int</em>) – The number of filter taps.</p></li>
<li><p><strong>cutoff_ratio</strong> (<em>float</em>) – Cut-off frequency ratio.</p></li>
<li><p><strong>beta</strong> (<em>float</em>) – Beta coefficient for kaiser window.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Impluse response of prototype filter (taps + 1,).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-gan-tts-melgan-melgan">
<span id="id20"></span><h2>espnet2.gan_tts.melgan.melgan<a class="headerlink" href="#espnet2-gan-tts-melgan-melgan" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.melgan.melgan"></span><p>MelGAN Modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.melgan.</code><code class="sig-name descname">MelGANDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1, out_channels: int = 1, kernel_sizes: List[int] = [5, 3], channels: int = 16, max_downsample_channels: int = 1024, bias: bool = True, downsample_scales: List[int] = [4, 4, 4, 4], nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.2}, pad: str = 'ReflectionPad1d', pad_params: Dict[str, Any] = {}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>MelGAN discriminator module.</p>
<p>Initilize MelGANDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of two kernel sizes. The prod will be used
for the first conv layer, and the first and the second kernel sizes
will be used for the last two layers. For example if kernel_sizes =
[5, 3], the first layer kernel size will be 5 * 3 = 15, the last two
layers’ kernel size will be 5 and 3, respectively.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Initial number of channels for conv layer.</p></li>
<li><p><strong>max_downsample_channels</strong> (<em>int</em>) – Maximum number of channels for downsampling
layers.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>downsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of downsampling scales.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>pad</strong> (<em>str</em>) – Padding function module name before dilated convolution layer.</p></li>
<li><p><strong>pad_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for padding function.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of output tensors of each layer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.melgan.</code><code class="sig-name descname">MelGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 80, out_channels: int = 1, kernel_size: int = 7, channels: int = 512, bias: bool = True, upsample_scales: List[int] = [8, 8, 2, 2], stack_kernel_size: int = 3, stacks: int = 3, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.2}, pad: str = 'ReflectionPad1d', pad_params: Dict[str, Any] = {}, use_final_nonlinear_activation: bool = True, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>MelGAN generator module.</p>
<p>Initialize MelGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of initial and final conv layer.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Initial number of channels for conv layer.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>stack_kernel_size</strong> (<em>int</em>) – Kernel size of dilated conv layers in residual
stack.</p></li>
<li><p><strong>stacks</strong> (<em>int</em>) – Number of stacks in a single residual stack.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>pad</strong> (<em>str</em>) – Padding function module name before dilated convolution layer.</p></li>
<li><p><strong>pad_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for padding function.</p></li>
<li><p><strong>use_final_nonlinear_activation</strong> (<em>torch.nn.Module</em>) – Activation function for
the final layer.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, channels, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, 1, T ** prod(upsample_scales)).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (T, in_channels).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (T ** prod(upsample_scales), out_channels).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows official implementation manner.
<a class="reference external" href="https://github.com/descriptinc/melgan-neurips/blob/master/mel2wav/modules.py">https://github.com/descriptinc/melgan-neurips/blob/master/mel2wav/modules.py</a></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.melgan.</code><code class="sig-name descname">MelGANMultiScaleDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1, out_channels: int = 1, scales: int = 3, downsample_pooling: str = 'AvgPool1d', downsample_pooling_params: Dict[str, Any] = {'count_include_pad': False, 'kernel_size': 4, 'padding': 1, 'stride': 2}, kernel_sizes: List[int] = [5, 3], channels: int = 16, max_downsample_channels: int = 1024, bias: bool = True, downsample_scales: List[int] = [4, 4, 4, 4], nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.2}, pad: str = 'ReflectionPad1d', pad_params: Dict[str, Any] = {}, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANMultiScaleDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>MelGAN multi-scale discriminator module.</p>
<p>Initilize MelGANMultiScaleDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>scales</strong> (<em>int</em>) – Number of multi-scales.</p></li>
<li><p><strong>downsample_pooling</strong> (<em>str</em>) – Pooling module name for downsampling of the
inputs.</p></li>
<li><p><strong>downsample_pooling_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the above
pooling module.</p></li>
<li><p><strong>kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of two kernel sizes. The sum will be used
for the first conv layer, and the first and the second kernel sizes
will be used for the last two layers.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Initial number of channels for conv layer.</p></li>
<li><p><strong>max_downsample_channels</strong> (<em>int</em>) – Maximum number of channels for downsampling
layers.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>downsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of downsampling scales.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>pad</strong> (<em>str</em>) – Padding function module name before dilated convolution layer.</p></li>
<li><p><strong>pad_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for padding function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANMultiScaleDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANMultiScaleDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs, which</dt><dd><p>consists of each layer output tensors.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[List[Tensor]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANMultiScaleDiscriminator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANMultiScaleDiscriminator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows official implementation manner.
<a class="reference external" href="https://github.com/descriptinc/melgan-neurips/blob/master/mel2wav/modules.py">https://github.com/descriptinc/melgan-neurips/blob/master/mel2wav/modules.py</a></p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-other-vocoder-init">
<span id="id21"></span><h2>espnet2.gan_tts.other_vocoder.__init__<a class="headerlink" href="#espnet2-gan-tts-other-vocoder-init" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-other-vocoder-istft-vocoder">
<span id="id22"></span><h2>espnet2.gan_tts.other_vocoder.istft_vocoder<a class="headerlink" href="#espnet2-gan-tts-other-vocoder-istft-vocoder" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-other-vocoder-bigvgan">
<span id="id23"></span><h2>espnet2.gan_tts.other_vocoder.bigvgan<a class="headerlink" href="#espnet2-gan-tts-other-vocoder-bigvgan" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.other_vocoder.bigvgan"></span><dl class="class">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.BigVGANAMPBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.other_vocoder.bigvgan.</code><code class="sig-name descname">BigVGANAMPBlock</code><span class="sig-paren">(</span><em class="sig-param">channels</em>, <em class="sig-param">kernel_size=3</em>, <em class="sig-param">dilation=(1</em>, <em class="sig-param">3</em>, <em class="sig-param">5)</em>, <em class="sig-param">rank=0</em>, <em class="sig-param">orig_freq=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#BigVGANAMPBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.BigVGANAMPBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.BigVGANAMPBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">x_mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#BigVGANAMPBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.BigVGANAMPBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.BigVGANAMPBlock.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#BigVGANAMPBlock.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.BigVGANAMPBlock.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.BigVGANDiscriminatorP">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.other_vocoder.bigvgan.</code><code class="sig-name descname">BigVGANDiscriminatorP</code><span class="sig-paren">(</span><em class="sig-param">period</em>, <em class="sig-param">kernel_size=5</em>, <em class="sig-param">stride=3</em>, <em class="sig-param">use_spectral_norm=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#BigVGANDiscriminatorP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.BigVGANDiscriminatorP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.BigVGANDiscriminatorP.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#BigVGANDiscriminatorP.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.BigVGANDiscriminatorP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.BigVGANDiscriminatorR">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.other_vocoder.bigvgan.</code><code class="sig-name descname">BigVGANDiscriminatorR</code><span class="sig-paren">(</span><em class="sig-param">resolution</em>, <em class="sig-param">use_spectral_norm=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#BigVGANDiscriminatorR"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.BigVGANDiscriminatorR" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.BigVGANDiscriminatorR.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#BigVGANDiscriminatorR.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.BigVGANDiscriminatorR.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.BigVGANDiscriminatorR.spectrogram">
<code class="sig-name descname">spectrogram</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#BigVGANDiscriminatorR.spectrogram"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.BigVGANDiscriminatorR.spectrogram" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.BigVGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.other_vocoder.bigvgan.</code><code class="sig-name descname">BigVGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">initial_channel</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">resblock_kernel_sizes</em>, <em class="sig-param">resblock_dilation_sizes</em>, <em class="sig-param">upsample_rates</em>, <em class="sig-param">upsample_initial_channel</em>, <em class="sig-param">upsample_kernel_sizes</em>, <em class="sig-param">gin_channels=0</em>, <em class="sig-param">rank=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#BigVGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.BigVGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.BigVGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">g=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#BigVGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.BigVGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.BigVGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#BigVGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.BigVGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.BigVGANMultiPeriodDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.other_vocoder.bigvgan.</code><code class="sig-name descname">BigVGANMultiPeriodDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">use_spectral_norm=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#BigVGANMultiPeriodDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.BigVGANMultiPeriodDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.BigVGANMultiPeriodDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#BigVGANMultiPeriodDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.BigVGANMultiPeriodDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.get_padding">
<code class="sig-prename descclassname">espnet2.gan_tts.other_vocoder.bigvgan.</code><code class="sig-name descname">get_padding</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">dilation=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#get_padding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.get_padding" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_tts.other_vocoder.bigvgan.init_weights">
<code class="sig-prename descclassname">espnet2.gan_tts.other_vocoder.bigvgan.</code><code class="sig-name descname">init_weights</code><span class="sig-paren">(</span><em class="sig-param">m</em>, <em class="sig-param">mean=0.0</em>, <em class="sig-param">std=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/bigvgan.html#init_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.bigvgan.init_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet2-gan-tts-other-vocoder-stft">
<span id="id24"></span><h2>espnet2.gan_tts.other_vocoder.stft<a class="headerlink" href="#espnet2-gan-tts-other-vocoder-stft" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.other_vocoder.stft"></span><p>BSD 3-Clause License
Copyright (c) 2017, Prem Seetharaman
All rights reserved.
* Redistribution and use in source and binary forms, with or without</p>
<blockquote>
<div><p>modification, are permitted provided that the following conditions are met:</p>
</div></blockquote>
<ul class="simple">
<li><p>Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.</p></li>
<li><p>Redistributions in binary form must reproduce the above copyright notice, this
list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.</p></li>
<li><p>Neither the name of the copyright holder nor the names of its
contributors may be used to endorse or promote products derived from this
software without specific prior written permission.</p></li>
</ul>
<p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR
ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>
<dl class="class">
<dt id="espnet2.gan_tts.other_vocoder.stft.STFT">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.other_vocoder.stft.</code><code class="sig-name descname">STFT</code><span class="sig-paren">(</span><em class="sig-param">filter_length=800</em>, <em class="sig-param">hop_length=200</em>, <em class="sig-param">win_length=800</em>, <em class="sig-param">window='hann'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/stft.html#STFT"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.stft.STFT" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>adapted from Prem Seetharaman’s <a class="reference external" href="https://github.com/pseeth/pytorch-stft">https://github.com/pseeth/pytorch-stft</a></p>
<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.stft.STFT.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">magnitude</em>, <em class="sig-param">phase</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/stft.html#STFT.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.stft.STFT.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.stft.STFT.inverse">
<code class="sig-name descname">inverse</code><span class="sig-paren">(</span><em class="sig-param">magnitude</em>, <em class="sig-param">phase</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/stft.html#STFT.inverse"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.stft.STFT.inverse" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.stft.STFT.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param">input_data</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/stft.html#STFT.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.stft.STFT.transform" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.other_vocoder.stft.TorchSTFT">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.other_vocoder.stft.</code><code class="sig-name descname">TorchSTFT</code><span class="sig-paren">(</span><em class="sig-param">filter_length=800</em>, <em class="sig-param">hop_length=200</em>, <em class="sig-param">win_length=800</em>, <em class="sig-param">window='hann'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/stft.html#TorchSTFT"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.stft.TorchSTFT" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.stft.TorchSTFT.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_data</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/stft.html#TorchSTFT.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.stft.TorchSTFT.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.stft.TorchSTFT.inverse">
<code class="sig-name descname">inverse</code><span class="sig-paren">(</span><em class="sig-param">magnitude</em>, <em class="sig-param">phase</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/stft.html#TorchSTFT.inverse"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.stft.TorchSTFT.inverse" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.other_vocoder.stft.TorchSTFT.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param">input_data</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/stft.html#TorchSTFT.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.stft.TorchSTFT.transform" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.gan_tts.other_vocoder.stft.window_sumsquare">
<code class="sig-prename descclassname">espnet2.gan_tts.other_vocoder.stft.</code><code class="sig-name descname">window_sumsquare</code><span class="sig-paren">(</span><em class="sig-param">window</em>, <em class="sig-param">n_frames</em>, <em class="sig-param">hop_length=200</em>, <em class="sig-param">win_length=800</em>, <em class="sig-param">n_fft=800</em>, <em class="sig-param">dtype=&lt;class 'numpy.float32'&gt;</em>, <em class="sig-param">norm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/other_vocoder/stft.html#window_sumsquare"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.other_vocoder.stft.window_sumsquare" title="Permalink to this definition">¶</a></dt>
<dd><p># from librosa 0.6
Compute the sum-square envelope of a window function at a given hop length.
This is used to estimate modulation effects induced by windowing
observations in short-time fourier transforms.
:param window: Window specification, as in <cite>get_window</cite>
:type window: string, tuple, number, callable, or list-like
:param n_frames: The number of analysis frames
:type n_frames: int &gt; 0
:param hop_length: The number of samples to advance between frames
:type hop_length: int &gt; 0
:param win_length: The length of the window function.  By default, this matches <cite>n_fft</cite>.
:type win_length: [optional]
:param n_fft: The length of each analysis frame.
:type n_fft: int &gt; 0
:param dtype: The data type of the output
:type dtype: np.dtype</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>wss</strong> – The sum-squared envelope of the window function</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>np.ndarray, shape=`(n_fft + hop_length * (n_frames - 1))`</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-gan-tts-vits-loss">
<span id="id25"></span><h2>espnet2.gan_tts.vits.loss<a class="headerlink" href="#espnet2-gan-tts-vits-loss" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-vits-flow">
<span id="id26"></span><h2>espnet2.gan_tts.vits.flow<a class="headerlink" href="#espnet2-gan-tts-vits-flow" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-vits-init">
<span id="id27"></span><h2>espnet2.gan_tts.vits.__init__<a class="headerlink" href="#espnet2-gan-tts-vits-init" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-vits-duration-predictor">
<span id="id28"></span><h2>espnet2.gan_tts.vits.duration_predictor<a class="headerlink" href="#espnet2-gan-tts-vits-duration-predictor" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-vits-text-encoder">
<span id="id29"></span><h2>espnet2.gan_tts.vits.text_encoder<a class="headerlink" href="#espnet2-gan-tts-vits-text-encoder" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-vits-transform">
<span id="id30"></span><h2>espnet2.gan_tts.vits.transform<a class="headerlink" href="#espnet2-gan-tts-vits-transform" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-vits-posterior-encoder">
<span id="id31"></span><h2>espnet2.gan_tts.vits.posterior_encoder<a class="headerlink" href="#espnet2-gan-tts-vits-posterior-encoder" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-vits-residual-coupling">
<span id="id32"></span><h2>espnet2.gan_tts.vits.residual_coupling<a class="headerlink" href="#espnet2-gan-tts-vits-residual-coupling" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-vits-vits">
<span id="id33"></span><h2>espnet2.gan_tts.vits.vits<a class="headerlink" href="#espnet2-gan-tts-vits-vits" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-vits-generator">
<span id="id34"></span><h2>espnet2.gan_tts.vits.generator<a class="headerlink" href="#espnet2-gan-tts-vits-generator" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-vits-monotonic-align-init">
<span id="id35"></span><h2>espnet2.gan_tts.vits.monotonic_align.__init__<a class="headerlink" href="#espnet2-gan-tts-vits-monotonic-align-init" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-vits-monotonic-align-setup">
<span id="id36"></span><h2>espnet2.gan_tts.vits.monotonic_align.setup<a class="headerlink" href="#espnet2-gan-tts-vits-monotonic-align-setup" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-style-melgan-init">
<span id="id37"></span><h2>espnet2.gan_tts.style_melgan.__init__<a class="headerlink" href="#espnet2-gan-tts-style-melgan-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.style_melgan.__init__"></span></section>
<section id="espnet2-gan-tts-style-melgan-style-melgan">
<span id="id38"></span><h2>espnet2.gan_tts.style_melgan.style_melgan<a class="headerlink" href="#espnet2-gan-tts-style-melgan-style-melgan" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.style_melgan.style_melgan"></span><p>StyleMelGAN Modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.style_melgan.style_melgan.</code><code class="sig-name descname">StyleMelGANDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">repeats: int = 2, window_sizes: List[int] = [512, 1024, 2048, 4096], pqmf_params: List[List[int]] = [[1, None, None, None], [2, 62, 0.267, 9.0], [4, 62, 0.142, 9.0], [8, 62, 0.07949, 9.0]], discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 16, 'downsample_scales': [4, 4, 4, 1], 'kernel_sizes': [5, 3], 'max_downsample_channels': 512, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.2}, 'out_channels': 1, 'pad': 'ReflectionPad1d', 'pad_params': {}}, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Style MelGAN disciminator module.</p>
<p>Initilize StyleMelGANDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>repeats</strong> (<em>int</em>) – Number of repititons to apply RWD.</p></li>
<li><p><strong>window_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of random window sizes.</p></li>
<li><p><strong>pqmf_params</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of list of Parameters for PQMF modules</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for base discriminator
module.</p></li>
<li><p><strong>use_weight_nom</strong> (<em>bool</em>) – Whether to apply weight normalization.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of discriminator outputs, #items in the list will be</dt><dd><p>equal to repeats * #discriminators.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANDiscriminator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.style_melgan.style_melgan.</code><code class="sig-name descname">StyleMelGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 128, aux_channels: int = 80, channels: int = 64, out_channels: int = 1, kernel_size: int = 9, dilation: int = 2, bias: bool = True, noise_upsample_scales: List[int] = [11, 2, 2, 2], noise_upsample_activation: str = 'LeakyReLU', noise_upsample_activation_params: Dict[str, Any] = {'negative_slope': 0.2}, upsample_scales: List[int] = [2, 2, 2, 2, 2, 2, 2, 2, 1], upsample_mode: str = 'nearest', gated_function: str = 'softmax', use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Style MelGAN generator module.</p>
<p>Initilize StyleMelGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input noise channels.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of auxiliary input channels.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of channels for conv layer.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of conv layers.</p></li>
<li><p><strong>dilation</strong> (<em>int</em>) – Dilation factor for conv layers.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>noise_upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of noise upsampling scales.</p></li>
<li><p><strong>noise_upsample_activation</strong> (<em>str</em>) – Activation function module name for noise
upsampling.</p></li>
<li><p><strong>noise_upsample_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for the
above activation function.</p></li>
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>upsample_mode</strong> (<em>str</em>) – Upsampling mode in TADE layer.</p></li>
<li><p><strong>gated_function</strong> (<em>str</em>) – Gated function used in TADEResBlock
(“softmax” or “sigmoid”).</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">z: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Auxiliary input tensor (B, channels, T).</p></li>
<li><p><strong>z</strong> (<em>Tensor</em>) – Input noise tensor (B, in_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T ** prod(upsample_scales)).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (T, in_channels).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (T ** prod(upsample_scales), out_channels).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-style-melgan-tade-res-block">
<span id="id39"></span><h2>espnet2.gan_tts.style_melgan.tade_res_block<a class="headerlink" href="#espnet2-gan-tts-style-melgan-tade-res-block" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.style_melgan.tade_res_block"></span><p>StyleMelGAN’s TADEResBlock Modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.style_melgan.tade_res_block.TADELayer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.style_melgan.tade_res_block.</code><code class="sig-name descname">TADELayer</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 64</em>, <em class="sig-param">aux_channels: int = 80</em>, <em class="sig-param">kernel_size: int = 9</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">upsample_factor: int = 2</em>, <em class="sig-param">upsample_mode: str = 'nearest'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/tade_res_block.html#TADELayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.tade_res_block.TADELayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>TADE Layer module.</p>
<p>Initilize TADELayer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channles.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of auxirialy channles.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv.</p></li>
<li><p><strong>upsample_factor</strong> (<em>int</em>) – Upsample factor.</p></li>
<li><p><strong>upsample_mode</strong> (<em>str</em>) – Upsample mode.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.tade_res_block.TADELayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/tade_res_block.html#TADELayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.tade_res_block.TADELayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>c</strong> (<em>Tensor</em>) – Auxiliary input tensor (B, aux_channels, T’).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, in_channels, T * in_upsample_factor).
Tensor: Upsampled aux tensor (B, in_channels, T * aux_upsample_factor).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.style_melgan.tade_res_block.TADEResBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.style_melgan.tade_res_block.</code><code class="sig-name descname">TADEResBlock</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 64</em>, <em class="sig-param">aux_channels: int = 80</em>, <em class="sig-param">kernel_size: int = 9</em>, <em class="sig-param">dilation: int = 2</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">upsample_factor: int = 2</em>, <em class="sig-param">upsample_mode: str = 'nearest'</em>, <em class="sig-param">gated_function: str = 'softmax'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/tade_res_block.html#TADEResBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.tade_res_block.TADEResBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>TADEResBlock module.</p>
<p>Initialize TADEResBlock module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channles.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of auxirialy channles.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv.</p></li>
<li><p><strong>upsample_factor</strong> (<em>int</em>) – Upsample factor.</p></li>
<li><p><strong>upsample_mode</strong> (<em>str</em>) – Upsample mode.</p></li>
<li><p><strong>gated_function</strong> (<em>str</em>) – Gated function type (softmax of sigmoid).</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.tade_res_block.TADEResBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/tade_res_block.html#TADEResBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.tade_res_block.TADEResBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>c</strong> (<em>Tensor</em>) – Auxiliary input tensor (B, aux_channels, T’).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, in_channels, T * in_upsample_factor).
Tensor: Upsampled auxirialy tensor (B, in_channels, T * in_upsample_factor).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-joint-joint-text2wav">
<span id="id40"></span><h2>espnet2.gan_tts.joint.joint_text2wav<a class="headerlink" href="#espnet2-gan-tts-joint-joint-text2wav" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.joint.joint_text2wav"></span><p>Joint text-to-wav module for end-to-end training.</p>
<dl class="class">
<dt id="espnet2.gan_tts.joint.joint_text2wav.JointText2Wav">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.joint.joint_text2wav.</code><code class="sig-name descname">JointText2Wav</code><span class="sig-paren">(</span><em class="sig-param">idim: int, odim: int, segment_size: int = 32, sampling_rate: int = 22050, text2mel_type: str = 'fastspeech2', text2mel_params: Dict[str, Any] = {'adim': 384, 'aheads': 2, 'conformer_activation_type': 'swish', 'conformer_dec_kernel_size': 31, 'conformer_enc_kernel_size': 7, 'conformer_pos_enc_layer_type': 'rel_pos', 'conformer_rel_pos_type': 'latest', 'conformer_self_attn_layer_type': 'rel_selfattn', 'decoder_concat_after': False, 'decoder_normalize_before': True, 'decoder_type': 'conformer', 'dlayers': 4, 'dunits': 1536, 'duration_predictor_chans': 384, 'duration_predictor_dropout_rate': 0.1, 'duration_predictor_kernel_size': 3, 'duration_predictor_layers': 2, 'elayers': 4, 'encoder_concat_after': False, 'encoder_normalize_before': True, 'encoder_type': 'conformer', 'energy_embed_dropout': 0.5, 'energy_embed_kernel_size': 1, 'energy_predictor_chans': 384, 'energy_predictor_dropout': 0.5, 'energy_predictor_kernel_size': 3, 'energy_predictor_layers': 2, 'eunits': 1536, 'gst_conv_chans_list': [32, 32, 64, 64, 128, 128], 'gst_conv_kernel_size': 3, 'gst_conv_layers': 6, 'gst_conv_stride': 2, 'gst_gru_layers': 1, 'gst_gru_units': 128, 'gst_heads': 4, 'gst_tokens': 10, 'init_dec_alpha': 1.0, 'init_enc_alpha': 1.0, 'init_type': 'xavier_uniform', 'langs': -1, 'pitch_embed_dropout': 0.5, 'pitch_embed_kernel_size': 1, 'pitch_predictor_chans': 384, 'pitch_predictor_dropout': 0.5, 'pitch_predictor_kernel_size': 5, 'pitch_predictor_layers': 5, 'positionwise_conv_kernel_size': 1, 'positionwise_layer_type': 'conv1d', 'postnet_chans': 512, 'postnet_dropout_rate': 0.5, 'postnet_filts': 5, 'postnet_layers': 5, 'reduction_factor': 1, 'spk_embed_dim': None, 'spk_embed_integration_type': 'add', 'spks': -1, 'stop_gradient_from_energy_predictor': False, 'stop_gradient_from_pitch_predictor': True, 'transformer_dec_attn_dropout_rate': 0.1, 'transformer_dec_dropout_rate': 0.1, 'transformer_dec_positional_dropout_rate': 0.1, 'transformer_enc_attn_dropout_rate': 0.1, 'transformer_enc_dropout_rate': 0.1, 'transformer_enc_positional_dropout_rate': 0.1, 'use_batch_norm': True, 'use_cnn_in_conformer': True, 'use_gst': False, 'use_macaron_style_in_conformer': True, 'use_masking': False, 'use_scaled_pos_enc': True, 'use_weighted_masking': False, 'zero_triu': False}, vocoder_type: str = 'hifigan_generator', vocoder_params: Dict[str, Any] = {'bias': True, 'channels': 512, 'global_channels': -1, 'kernel_size': 7, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'upsample_kernel_sizes': [16, 16, 4, 4], 'upsample_scales': [8, 8, 2, 2], 'use_additional_convs': True, 'use_weight_norm': True}, use_pqmf: bool = False, pqmf_params: Dict[str, Any] = {'beta': 9.0, 'cutoff_ratio': 0.142, 'subbands': 4, 'taps': 62}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, use_feat_match_loss: bool = True, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, use_mel_loss: bool = True, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_text2mel: float = 1.0, lambda_adv: float = 1.0, lambda_feat_match: float = 2.0, lambda_mel: float = 45.0, cache_generator_outputs: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/joint/joint_text2wav.html#JointText2Wav"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.joint.joint_text2wav.JointText2Wav" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.gan_tts.abs_gan_tts.AbsGANTTS" title="espnet2.gan_tts.abs_gan_tts.AbsGANTTS"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.gan_tts.abs_gan_tts.AbsGANTTS</span></code></a></p>
<p>General class to jointly train text2mel and vocoder parts.</p>
<p>Initialize JointText2Wav module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input vocabrary size.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Acoustic feature dimension. The actual output channels will
be 1 since the model is the end-to-end text-to-wave model but for the
compatibility odim is used to indicate the acoustic feature dimension.</p></li>
<li><p><strong>segment_size</strong> (<em>int</em>) – Segment size for random windowed inputs.</p></li>
<li><p><strong>sampling_rate</strong> (<em>int</em>) – Sampling rate, not used for the training but it will
be referred in saving waveform during the inference.</p></li>
<li><p><strong>text2mel_type</strong> (<em>str</em>) – The text2mel model type.</p></li>
<li><p><strong>text2mel_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for text2mel model.</p></li>
<li><p><strong>use_pqmf</strong> (<em>bool</em>) – Whether to use PQMF for multi-band vocoder.</p></li>
<li><p><strong>pqmf_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for PQMF module.</p></li>
<li><p><strong>vocoder_type</strong> (<em>str</em>) – The vocoder model type.</p></li>
<li><p><strong>vocoder_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for vocoder model.</p></li>
<li><p><strong>discriminator_type</strong> (<em>str</em>) – Discriminator type.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for discriminator.</p></li>
<li><p><strong>generator_adv_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for generator
adversarial loss.</p></li>
<li><p><strong>discriminator_adv_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for
discriminator adversarial loss.</p></li>
<li><p><strong>use_feat_match_loss</strong> (<em>bool</em>) – Whether to use feat match loss.</p></li>
<li><p><strong>feat_match_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for feat match loss.</p></li>
<li><p><strong>use_mel_loss</strong> (<em>bool</em>) – Whether to use mel loss.</p></li>
<li><p><strong>mel_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for mel loss.</p></li>
<li><p><strong>lambda_text2mel</strong> (<em>float</em>) – Loss scaling coefficient for text2mel model loss.</p></li>
<li><p><strong>lambda_adv</strong> (<em>float</em>) – Loss scaling coefficient for adversarial loss.</p></li>
<li><p><strong>lambda_feat_match</strong> (<em>float</em>) – Loss scaling coefficient for feat match loss.</p></li>
<li><p><strong>lambda_mel</strong> (<em>float</em>) – Loss scaling coefficient for mel loss.</p></li>
<li><p><strong>cache_generator_outputs</strong> (<em>bool</em>) – Whether to cache generator outputs.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_lengths: torch.Tensor</em>, <em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">forward_generator: bool = True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/espnet2/gan_tts/joint/joint_text2wav.html#JointText2Wav.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform generator forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (B, T_feats, aux_channels).</p></li>
<li><p><strong>feats_lengths</strong> (<em>Tensor</em>) – Feature length tensor (B,).</p></li>
<li><p><strong>speech</strong> (<em>Tensor</em>) – Speech waveform tensor (B, T_wav).</p></li>
<li><p><strong>speech_lengths</strong> (<em>Tensor</em>) – Speech length tensor (B,).</p></li>
<li><p><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>loss (Tensor): Loss scalar tensor.</p></li>
<li><p>stats (Dict[str, float]): Statistics to be monitored.</p></li>
<li><p>weight (Tensor): Weight tensor to summarize losses.</p></li>
<li><p>optim_idx (int): Optimizer index (0 for G and 1 for D).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/joint/joint_text2wav.html#JointText2Wav.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Run inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>Tensor</em>) – Input text index tensor (T_text,).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>wav (Tensor): Generated waveform tensor (T_wav,).</p></li>
<li><p>feat_gan (Tensor): Generated feature tensor (T_text, C).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.require_raw_speech">
<em class="property">property </em><code class="sig-name descname">require_raw_speech</code><a class="headerlink" href="#espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.require_raw_speech" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether or not speech is required.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.require_vocoder">
<em class="property">property </em><code class="sig-name descname">require_vocoder</code><a class="headerlink" href="#espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.require_vocoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether or not vocoder is required.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-joint-init">
<span id="id41"></span><h2>espnet2.gan_tts.joint.__init__<a class="headerlink" href="#espnet2-gan-tts-joint-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.joint.__init__"></span></section>
<section id="espnet2-gan-tts-jets-loss">
<span id="id42"></span><h2>espnet2.gan_tts.jets.loss<a class="headerlink" href="#espnet2-gan-tts-jets-loss" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-jets-init">
<span id="id43"></span><h2>espnet2.gan_tts.jets.__init__<a class="headerlink" href="#espnet2-gan-tts-jets-init" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-jets-length-regulator">
<span id="id44"></span><h2>espnet2.gan_tts.jets.length_regulator<a class="headerlink" href="#espnet2-gan-tts-jets-length-regulator" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-jets-jets">
<span id="id45"></span><h2>espnet2.gan_tts.jets.jets<a class="headerlink" href="#espnet2-gan-tts-jets-jets" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-jets-alignments">
<span id="id46"></span><h2>espnet2.gan_tts.jets.alignments<a class="headerlink" href="#espnet2-gan-tts-jets-alignments" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-jets-multi-emotion-generator">
<span id="id47"></span><h2>espnet2.gan_tts.jets.multi_emotion_generator<a class="headerlink" href="#espnet2-gan-tts-jets-multi-emotion-generator" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-jets-generator">
<span id="id48"></span><h2>espnet2.gan_tts.jets.generator<a class="headerlink" href="#espnet2-gan-tts-jets-generator" title="Permalink to this headline">¶</a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="espnet2.asr.html" class="btn btn-neutral float-left" title="espnet2.asr package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="espnet2.lm.html" class="btn btn-neutral float-right" title="espnet2.lm package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Shinji Watanabe.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>